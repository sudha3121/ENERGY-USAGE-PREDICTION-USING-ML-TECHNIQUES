# -*- coding: utf-8 -*-
"""ML_Final_Energy_Prediction_(2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HEqKew-tEyyOeObg9uqDKuQ1h-3_LsbU

**Objective: Predicting Energy Consumption: Predict energy consumption based on historical data.**

Step 1: Importing the Relevant Libraries

Step 2: Data Download & Data Inspection

Step 3: Exploratory Data Analysis

Step 4: Feature selection

Step 5: Feature engineering

Step 6: Train and Test split

Step 7: Model training, Croos validation and hyperparameter tuning

Step 8: Model explainability

Step 9: Conclusion
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Step 1: Importing the Relevant Libraries**"""

# Commented out IPython magic to ensure Python compatibility.
# Import Libraries for analysis and visualisation
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
# %matplotlib inline

## to import datetime library
from datetime import datetime
import datetime as dt

## Library of warnings would assist in ignoring warnings issued
import warnings
warnings.filterwarnings('ignore')

#Import necessary statistical libraries
import scipy.stats as stats
import statsmodels.api as sm
from scipy.stats import norm
#import libraries for ML-Model
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import  MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score,make_scorer
from sklearn.linear_model import  LinearRegression, Lasso, Ridge
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import  BaggingRegressor, ExtraTreesRegressor, RandomForestRegressor,StackingRegressor
from sklearn.model_selection import GridSearchCV
from xgboost import XGBRegressor
import lightgbm
from lightgbm import LGBMRegressor
# libraries for save the model
import pickle

pip install dask[dataframe]

#installing package
!pip install scikit-optimize

"""**Step 2: Data Download & Data Inspection**"""

#load the dataset from drive
filepath='/content/drive/MyDrive/data_application_energy.csv'
df=pd.read_csv(filepath)

df.head()

df.shape

df.info()

"""We have 29 columns and maximum columns are numerical except date

We have to convert the date column into datetime format
"""

# Missing Values/Null Values Count
df.isnull().sum()

# Visualizing the missing values
msno.bar(df, color='green',sort='ascending', figsize=(15,5), fontsize=15)

"""The dataset provided contains 29 columns and 19735 rows and does not have any missing or duplicate values.
The goal is to predict the energy use of appliances. Demand prediction involves analytical studies on the probability of house temperature and humidity conditions, which were monitored with a ZigBee wireless sensor network for 10 minutes for about 4.5 months.

There are no duplicate columns

There are no missing values
"""

#rename the columns
df.rename(columns={'T1': 'temp_kitchen', 'RH_1':'hu_Kitchen', 'T2':'temp_living_room', 'RH_2': 'hu_living', 'T3':'temp_Laundry_room',
       'RH_3':'hu_laundry', 'T4':'temp_office_room', 'RH_4':'hu_office', 'T5':'temp_bathroom', 'RH_5':'hu_bath', 'T6':'temp_build_out'
       , 'RH_6':'hu_build_out', 'T7':'temp_ironing_room', 'RH_7':'hu_ironing_room', 'T8':'temp_teen_room',
       'RH_8':'hu_teen', 'T9':'temp_parents_room', 'RH_9':'hu_parent', 'T_out':'temp_out', 'RH_out':'out_humidity'},inplace = True)

# Changing the data format of date column
df['date']=pd.to_datetime(df['date'])

#Getting the months and days from date

df['month'] = df['date'].dt.month
df['weekday'] = df['date'].dt.weekday
df['hour'] = df['date'].dt.hour

#drop the date column
df.drop('date',axis=1,inplace=True)

#separate column list for better analysis
temp_cols=['temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','temp_build_out','temp_ironing_room','temp_teen_room','temp_parents_room']
hu_cols=['hu_Kitchen','hu_living','hu_laundry', 'hu_office','hu_bath','hu_build_out','hu_ironing_room','hu_teen','hu_parent']
light_cols=['light']
weather_cols=['temp_out','out_humidity',"Tdewpoint","Press_mm_hg","Windspeed","Visibility"]
date_col = ['month','weekday','hour']
random_col = ["rv1","rv2"]

#look at first five rows after rename the column
df.head()

#Appliance Energy Column
fig,ax=plt.subplots(2,2,figsize=(15,10))

#Distribution of Appliances
dist=sns.distplot(df['Appliances'],ax=ax[0,0])
dist.set_title('Distribution of Appliances Energy')

#Average Appliances Energy over month
month_eng=pd.DataFrame(df.groupby('month')['Appliances'].mean()).reset_index()
sns.violinplot(x=df['month'],y=df['Appliances'], ax=ax[0,1])

#Average Appliances Energy over weekdays
weekday_eng=pd.DataFrame(df.groupby('weekday')['Appliances'].mean()).reset_index()
#sns.barplot(x=weekday_eng['weekday'],y=weekday_eng['Appliances'],ax=ax[1,0])
sns.boxplot(x=df['weekday'],y=df['Appliances'],ax=ax[1,0])
#Average Appliances Energy over hours
hour_eng=pd.DataFrame(df.groupby('hour')['Appliances'].mean()).reset_index()
sns.barplot(x=hour_eng['hour'],y=hour_eng['Appliances'],ax=ax[1,1])

"""Appliances Enegry has positive skewness. A log transformation can make it normal. Most of the values are around 100 Wh. Outliers are also present in the column.

In the month of January, the energy usage is high compared to the other months, and February has low energy consumption.

On Thursday and Saturday, the energy usage is high compared to the other days, and Tuesday has low energy consumption.

In the hours of the day, 8 hrs to 21 hrs have high energy consumption.
"""

#Temperature columns (Univariate+Bivariate)
n=len(temp_cols)
fig,ax=plt.subplots(len(temp_cols),2,figsize=(20,40))
for i,col in enumerate(temp_cols):
  #univariate of the columns
  dist=sns.distplot(df[col],ax=ax[i,0])
  ax[i,0].axvline(df[col].mean(), color='orange', linestyle='dashed', linewidth=2)
  ax[i,0].axvline(df[col].median(), color='green', linestyle='dashed', linewidth=2)
  #Bivariate Analysis the Appliance Energy
  #lineplot
  scatter=sns.lineplot(data=df,x=col,y='Appliances',color='green',ax=ax[i,1]);

"""All Temperature columns are followed normally distribution except parents rooms temperature
Inside buliding mean and median value of all room temperature lies between 19 to 22 degree celcius
Outside buliding mean and median value of temperature lies between 6 to 7 degree celcius
The lines in nearly all of the columns follow the same pattern.
It could be due to the same type of relationship between temperature variables and the Appliances Energy Consumption.
"""

#Humidity columns (Univariate+Bivariate)
fig,ax=plt.subplots(len(hu_cols),2,figsize=(20,40))
for i,col in enumerate(hu_cols):
  #univariate of the columns
  dist=sns.distplot(df[col],ax=ax[i,0])
  ax[i,0].axvline(df[col].mean(), color='orange', linestyle='dashed', linewidth=2)
  ax[i,0].axvline(df[col].median(), color='green', linestyle='dashed', linewidth=2)
  #Bivariate Analysis the Appliance Energy
  #lineplot
  scatter=sns.scatterplot(data=df,x=col,y='Appliances',color='green',ax=ax[i,1]);

"""All humidity distribution is follwed normal distribution except outside building humidity.
In inside building the mean and median value of humidity distribution lies between 35 to 45 percent,except bathroom humidity and it is near about 50 percent.
For outside building humidity, the mean and median value is around 55 percent.
For inside building low and high humidity causes low consumption of appliances energy. otherwise it causes high spreading data of energy consumption.
For outside building humidity energy consumption data is widely spread irresective of humidity.
"""

# Correlation Heatmap visualization code
plt.figure(figsize=(25,15))
correlation = df.corr()
sns.heatmap(correlation, annot=True, cmap='coolwarm',linewidth=0.8)
plt.show()

"""Temprature columns : It is clear from the heatmap that four columns have a high degree of correlation with parent_room_temperature that are temp_Laundry_room,temp_bathroom,temp_ironing_room,temp_teen_room also temp_build_out & temp_out has high correlation. Hence temp_build_out & temp_parents_room is to be removed from training set as information provided by them can be provided by other features.
Humidity columns : For each and every humidity columns, we see moderate correlation which is workable.
Weather_columns: Visibility, Tdewpoint, Press_mm_hg have low correlation values
Random variables column : Similar to the trend that we have seen in the weather columns we have low correlations

**Hypothetical test**

Null Hypothesis: The mean temperature in kitchen is greater than normal room temperature.

Alternate Hypothesis: The temperature in Kitchen is at max room temperature and it can not be above it.
"""

#collect the kitchen temperature
kitchen_rand= df['temp_kitchen'].sample(1000)
N=len(kitchen_rand)
#mean of the sample
kitchen_rand_mean= kitchen_rand.mean()
#Normal room temperature
nrt = 20
# the standard deviation for population
std_pop = df['temp_kitchen'].std()
# Perform Statistical Test to obtain P-Value

Z_stat = ((kitchen_rand_mean - nrt)/(std_pop/np.sqrt(N)))
print(f'Z_score is {Z_stat} ')

P_value=norm.cdf(Z_stat,0,1)
print(f'P_value is {P_value} ')

"""normal cumulative distribution function with the mean and standard deviation of a random sample to calculate the Z statistics for a particular proportion and then find its P_value.
Z statistics provides precise values for testing the hypothesis. It is easily comparable to its critical levels.According the result null hypothesis can rejected.

**Step 3: Exploratory Data Analysis**
"""

df.hist(bins=20, figsize=(40,30))
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12,7))

sns.set_style('whitegrid')
sns.set_context('talk', font_scale=1.2)

sns.pairplot(df, kind='scatter')

plt.suptitle('Scatter Plot Matrix of Appliances energy prediction')

plt.show() # Scatter plot that shows the plotting between the target variable and feature variables

# Checking Skewness
df['Appliances'].skew()

fig,ax=plt.subplots(1,3, figsize=(15,8))
sns.distplot(df.Appliances,ax=ax[0])
sns.boxplot(df.Appliances, ax=ax[1])
stats.probplot(df.Appliances,plot=plt)

#Using transformation method on dependent variable
fig,ax=plt.subplots(1,3, figsize=(15,8))
sns.distplot(np.log10(df.Appliances),ax=ax[0])
sns.boxplot(np.log10(df.Appliances), ax=ax[1])
stats.probplot(df.Appliances,plot=plt)

df.skew()

# Freq distribution of all data
fig, ax = plt.subplots(figsize=(15,15))
pd.DataFrame.hist(data=df,ax=ax)
plt.tight_layout()

# Energy consumption by hour
energy_by_hour = df.groupby('hour')['Appliances'].mean()
plt.figure(figsize=(10, 6))
sns.lineplot(x=energy_by_hour.index, y=energy_by_hour.values)
plt.title('Energy Consumption by Hour')
plt.xlabel('Hour')
plt.ylabel('Average Energy Consumption')
plt.show()

# Energy consumption (Daywise and phase-wise)
df['Phase'] = pd.cut(df['hour'], bins=[0, 6, 9, 17, 21, 24], labels=['Night', 'Morning', 'Afternoon', 'Evening', 'Late Night'])
energy_by_phase_day = df.groupby(['weekday', 'Phase'])['Appliances'].mean().unstack()
energy_by_phase_day.plot(kind='bar', figsize=(12, 6), stacked=True)
plt.title('Energy Consumption by Day and Phase of the Day')
plt.xlabel('weekday')
plt.ylabel('Average Energy Consumption')
plt.legend(title='Phase of the Day')
plt.show()

#Energy Consumption vs Date
date=df.groupby(df.month)["Appliances"].sum().sort_values(ascending=False)
date

#Energy Consumption vs Windspeed
Windspeed=df.groupby(df.month)["Windspeed"].sum().sort_values(ascending=False)
Windspeed

sns.relplot(y='Appliances', x='hour', data=df, kind='line', hue='weekday', height=7, aspect=1.7)
plt.show()

"""**Step 4: Feature selection**"""

df.head()

#removing light column
#df.drop("lights",axis=1,inplace=True)

df.shape

#Multicollinearity
from statsmodels.stats.outliers_influence import variance_inflation_factor
def calc_vif(X):

    # Calculating VIF
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

    return(vif)

calc_vif(df[[i for i in df.describe().columns if i not in ['Appliances']]]).sort_values(by='VIF',ascending=False)

#In data-set there are Multicollinearity features present

"""**Step 5: Feature engineering**"""

#Handling Outliers
#copy the dataframe
df=df.copy()
col_list=list(df.describe().columns)

#find the columns have outlier with boxplot
plt.figure(figsize=(25, 20))
plt.suptitle("Box Plot", fontsize=18, y=0.95)

for n, ticker in enumerate(col_list):

    ax = plt.subplot(8, 4, n + 1)

    plt.subplots_adjust(hspace=0.5, wspace=0.2)

    sns.boxplot(x=df[ticker],color='g', ax = ax)

    # chart formatting
    ax.set_title(ticker.upper())

"""The majority of appliances use between 0 and 200 Wh of energy. It is apparent that many variables contain outliers.

Outliers can be found in all temperature column.

Outliers also exist in all humidity columns,Windspeed, Tdewpoint, Visibility, and the variable of interest Outliers exist in appliances as well.
"""

# Handling Outliers & Outlier treatments
for ftr in col_list:
  print(ftr,'\n')
  q_25= np.percentile(df[ftr], 25)
  q_75 = np.percentile(df[ftr], 75)
  iqr = q_75 - q_25
  print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q_25, q_75, iqr))
  # calculate the outlier cutoff
  cut_off = iqr * 1.5
  lower = q_25 - cut_off
  upper = q_75 + cut_off
  print(f"\nlower = {lower} and upper = {upper} \n ")
  # identify outliers
  outliers = [x for x in df[ftr] if x < lower or x > upper]
  print('Identified outliers: %d' % len(outliers))
  #removing outliers
  if len(outliers)!=0:

    def bin(row):
      if row[ftr]> upper:
        return upper
      if row[ftr] < lower:
        return lower
      else:
        return row[ftr]



    df[ftr] =  df.apply (lambda row: bin(row), axis=1)
    print(f"{ftr} Outliers Removed")
  print("\n-------\n")

plt.figure(figsize=(25, 20))
plt.suptitle("Box Plot without Outliers", fontsize=18, y=0.95)
#plot the all figures in loop with boxplot
for n, ticker in enumerate(col_list):

    ax = plt.subplot(8, 4, n + 1)

    plt.subplots_adjust(hspace=0.5, wspace=0.2)

    sns.boxplot(x=df[ticker],color='orange' ,ax = ax)

    # chart formatting
    ax.set_title(ticker.upper())

"""The box plot is a handy graphical depiction for describing the behaviour of data in the middle and at the ends of distributions. The box plot employs the median as well as the lower and upper quartiles (defined as the 25th and 75th percentiles). If the lower quartile is Q1 and the upper quartile is Q3, the difference (Q3 — Q1) is known as the interquartile range, or IQ. A box plot is made by drawing a box between the higher and lower quartiles and a solid line across the box to find the median. The following quantities (referred to as fences) are required for recognising extreme values in the distribution's tails:

lower fence: Q1–1.5*IQ

upper fence: Q3 + 1.5*IQ
"""

#Manipulate Features to minimize feature correlation
# create new features
# create a column average building temperature based on all temperature
df['Average_building_Temperature']=df[['temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','temp_ironing_room','temp_teen_room','temp_parents_room']].mean(axis=1)
#create a column of difference between outside and inside temperature
df['Temperature_difference']=abs(df['Average_building_Temperature']-df['temp_build_out'])

#create a column average building humidity
df['Average_building_humidity']=df[['hu_Kitchen','hu_living','hu_laundry', 'hu_office','hu_bath','hu_ironing_room','hu_teen','hu_parent']].mean(axis=1)
#create a column of difference between outside and inside building humidity
df['Humidity_difference']=abs(df['hu_build_out']-df['Average_building_humidity'])

"""Firstly, we are going to drop two random variable column because they have no part in energy prediction.After that we will check multicolinearity among remaining columns."""

#drop rv1 and rv2
df.drop('rv1',axis=1,inplace=True)
df.drop('rv2',axis=1,inplace=True)

#create a function to check multicolinearity
from statsmodels.stats.outliers_influence import variance_inflation_factor
def calc_vif(X):

    # Calculating VIF
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [round(variance_inflation_factor(X.values, i),2) for i in range(X.shape[1])]

    return(vif)

#check multicolinearuty
calc_vif(df[[i for i in df.describe().columns if i not in ['Appliances']]]).sort_values(by='VIF',ascending=False)

"""It's look like lots of column is replica of one another.so we are going to remove atleast half of them"""

#check Multicolinearity
calc_vif(df[[i for i in df.describe().columns if i not in ['Appliances','lights','temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','hu_Kitchen','hu_living','hu_laundry','hu_office','hu_bath','temp_build_out','Average_building_Temperature']]]).sort_values(by='VIF',ascending=False)

#check Multicolinearity
calc_vif(df[[i for i in df.describe().columns if i not in ['Appliances','lights','temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','hu_Kitchen','hu_living','hu_laundry','hu_office','hu_bath','temp_build_out','Average_building_Temperature','Press_mm_hg','temp_parents_room','Average_building_humidity','temp_ironing_room','out_humidity']]]).sort_values(by='VIF',ascending=False)

#check Multicolinearity
calc_vif(df[[i for i in df.describe().columns if i not in ['Appliances','lights','temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','hu_Kitchen','hu_living','hu_laundry','hu_office','hu_bath','temp_build_out','Average_building_Temperature','Press_mm_hg','temp_parents_room','Average_building_humidity','temp_ironing_room','out_humidity','hu_teen','hu_parent','temp_teen_room','hu_ironing_room']]]).sort_values(by='VIF',ascending=False)

#check Multicolinearity
calc_vif(df[[i for i in df.describe().columns if i not in ['Appliances','lights','temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','hu_Kitchen','hu_living','hu_laundry','hu_office','hu_bath','temp_build_out','Average_building_Temperature','Press_mm_hg','temp_parents_room','Average_building_humidity','temp_ironing_room','out_humidity','hu_teen','hu_parent','temp_teen_room','hu_ironing_room','Temperature_difference','Visibility']]]).sort_values(by='VIF',ascending=False)

#check Multicolinearity
calc_vif(df[[i for i in df.describe().columns if i not in ['Appliances','lights','temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','hu_Kitchen','hu_living','hu_laundry','hu_office','hu_bath','temp_build_out','Average_building_Temperature','Press_mm_hg','temp_parents_room','Average_building_humidity','temp_ironing_room','out_humidity','hu_teen','hu_parent','temp_teen_room','hu_ironing_room','Temperature_difference','temp_out','Visibility']]]).sort_values(by='VIF',ascending=False)

# Select your features wisely to avoid overfitting
df_removed=df[[i for i in df.describe().columns if i not in ['lights','temp_kitchen','temp_living_room','temp_Laundry_room','temp_office_room','temp_bathroom','hu_Kitchen','hu_living','hu_laundry','hu_office','hu_bath','temp_build_out','Average_building_Temperature','Press_mm_hg','temp_parents_room','Average_building_humidity','temp_ironing_room','out_humidity','hu_teen','hu_parent','temp_teen_room','hu_ironing_room','Temperature_difference','temp_out','Visibility']]]

df_removed.head()

"""I use Variance Inflation Factor(VIF) for feature selection.

The Variance Inflation Factor (VIF) is used to detect multicollinearity. Variance inflation factors (VIF) quantify how much the variance of predicted regression coefficients is inflated when the predictor variables are not linearly connected.

According to above stated criteria, we have removed column one by one and check whether all the features vif value is less than 10 or not.Once all the vif value of features is below 10 then we stop the checking multicolinearity. Important features for the project that we have found are Appliances	hu_build_out	Windspeed	Tdewpoint	rv1	month	weekday	hour	Humidity_difference.
"""

#check distribution  of all independent features
for col in df_removed.describe().columns:
  fig=plt.figure(figsize=(9,6))
  ax=fig.gca()
  feature= (df_removed[col])
  sns.distplot(df_removed[col])
  ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)
  ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)
  ax.set_title(col)
plt.show()

from scipy.stats import boxcox
from scipy.stats import boxcox_normmax

# Determine the optimal lambda value for the Box-Cox transformation
optimal_lambda = boxcox_normmax(df_removed['Appliances'])

# Apply the Box-Cox transformation to the 'Appliances' column using the optimal lambda
df_removed['Appliances'] = boxcox(df_removed['Appliances'], optimal_lambda)

# Transform Your data

df_removed['Windspeed']=df_removed['Windspeed'].apply(lambda x:np.log10(x+1))

"""Appliance and Windspeed features of the data need to be transformed,because they are skewd.We have use log transformation with them. Other features follwed normal distribution,symmetrical around y axis and some of them does not have any resemblace with normal distribution. They will be scalled in upcoming part."""

# check the distribution of the features after transformation
for col in df_removed.describe().columns:
  fig=plt.figure(figsize=(9,6))
  ax=fig.gca()
  feature= (df_removed[col])
  sns.distplot(df_removed[col])
  ax.axvline(feature.mean(),color='magenta', linestyle='dashed', linewidth=2)
  ax.axvline(feature.median(),color='cyan', linestyle='dashed', linewidth=2)
  ax.set_title(col)
plt.show()

"""**Step 6: Train and Test split**"""

# Split your data to train and test. Choose Splitting ratio wisely.
X=df_removed.drop('Appliances',axis=1)
y=df_removed['Appliances']
X_train,X_test,y_train,y_test_=train_test_split(X,y,test_size=0.2,random_state=0)

# Scaling data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled_ = scaler.transform(X_test)

#spearate two rows from test  set to check it with best model
X_test_best=X_test_scaled_[-2:]
y_test_best=y_test_[-2:]
X_test_scaled=X_test_scaled_[:-2]
y_test=y_test_[:-2]

#check shape of all separated variables
print(X_test_best.shape)
print(y_test_best.shape)
print(X_test_scaled.shape)
print(y_test.shape)

x_test_scaled=X_test_scaled[:-2]
x_test_scaled.shape

"""**Step 7: Model training, Croos validation and hyperparameter tuning**"""

# ML Model - 1 Implementation
#LinearRegresseion
lr=LinearRegression()
# Fit the LinearRegression
lr.fit(X_train_scaled,y_train)
#predict the target values of train data
lr_train=lr.predict(X_train_scaled)
# Predict the target values for the test data
y_pred_lr = lr.predict(X_test_scaled)
#Evaluate the model using
mse_lr_train=mean_squared_error(y_train,lr_train)
mse_lr_test = mean_squared_error(y_test, y_pred_lr)
r2_lr_train=r2_score(y_train,lr_train)
r2_lr_test = r2_score(y_test, y_pred_lr)

print("LinearRegression Mean Squared Error:",mse_lr_test)
print("LinearRegression R^2 Score:",r2_lr_test)


##Ridge
ridge = Ridge()
# Fit the Ridge model
ridge.fit(X_train_scaled, y_train)
#predict the target values of train data
r_train=ridge.predict(X_train_scaled)
# Predict  values for the test data
y_pred_r = ridge.predict(X_test_scaled)
# Evaluate the model using metrics
mse_r_train=mean_squared_error(y_train,r_train)
mse_r_test =mean_squared_error(y_test, y_pred_r)
r2_r_train=r2_score(y_train,r_train)
r2_r_test = r2_score(y_test, y_pred_r)

print("Ridge Mean Squared Error:",mse_r_test)
print("Ridge R^2 Score:",r2_r_test)


#Lasso
lasso = Lasso()
# Fit the Lasso model on the training data
lasso.fit(X_train_scaled, y_train)
#predict the target values of train data
l_train=ridge.predict(X_train_scaled)
# Predict the target values for the test data
y_pred_l = lasso.predict(X_test_scaled)
# Evaluate the model using metrics
mse_l_train=mean_squared_error(y_train,l_train)
mse_l_test = mean_squared_error(y_test, y_pred_l)
r2_l_train=r2_score(y_train,l_train)
r2_l_test = r2_score(y_test, y_pred_l)

print("Lasso Mean Squared Error:",mse_l_test)
print("Lasso R^2 Score:",r2_l_test)

#checking the coefficients
print("The Coefficients obtain from linearrgression model",lr.coef_)
print("The Coefficients obtain from Ridge model",ridge.coef_)
print("The Coefficients obtain from Lasso model",lasso.coef_)

#checking the intercepts
print("The Intercepts obtain from linearrgression model",lr.intercept_)
print("The Intercepts obtain from Ridge model",ridge.intercept_)
print("The Intercepts obtain from Lasso model",lasso.intercept_)

# Visualizing evaluation Metric Score chart
## Plot the predicted vs actual values
plt.figure(figsize=(20,7))
plt.plot(((y_pred_lr)[500:550]),color='indigo')
plt.plot(((y_pred_r)[500:550]),color='green')
plt.plot(((y_pred_l)[500:550]),color='blue')
plt.plot((np.array((y_test)[500:550])),color='red')
plt.legend(["LinearRegression","Ridge","Lasso","Actual"])
plt.title("Sample of Actual vs Predicted of LinearRgression" )
plt.show()

# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
ridge_params = {'alpha': [0.001, 0.01,0.1,0.5, 1,2,5]}
lasso_params = {'alpha': [0.0001, 0.001,0.01, 0.1,0.2,0.5,1]}

# Create Ridge and Lasso regression objects
ridge = Ridge()
lasso = Lasso()

# Define the scoring method using 'make_scorer' with MAPE
mape_scorer = make_scorer(mean_squared_error, greater_is_better=False)

# GridSearchCV for Ridge model using MAPE scoring
ridge_cv = GridSearchCV(ridge, param_grid=ridge_params, scoring=mape_scorer)

# GridSearchCV for Lasso model using MAPE scoring
lasso_cv = GridSearchCV(lasso, param_grid=lasso_params, scoring=mape_scorer)

# Fit the models using GridSearchCV
ridge_cv.fit(X_train_scaled, y_train)
lasso_cv.fit(X_train_scaled, y_train)
# Get the best hyperparameters and fit the models again using the best hyperparameters
ridge_best = Ridge(alpha=ridge_cv.best_params_['alpha']).fit(X_train_scaled, y_train)
lasso_best = Lasso(alpha=lasso_cv.best_params_['alpha']).fit(X_train_scaled, y_train)

#predict the train data using the best models
y_train_ridge=ridge_best.predict(X_train_scaled)
y_train_lasso = lasso_best.predict(X_train_scaled)
# Predict  values for the test data using the best models
y_pred_ridge = ridge_best.predict(X_test_scaled)
y_pred_lasso = lasso_best.predict(X_test_scaled)

# Evaluate
mse_ridge_train = mean_squared_error(y_train, y_train_ridge)
mse_ridge_test = mean_squared_error(y_test, y_pred_ridge)
r2_ridge_train = r2_score(y_train, y_train_ridge)
r2_ridge_test = r2_score(y_test, y_pred_ridge)
mse_lasso_train = mean_squared_error(y_train, y_train_lasso)
mse_lasso_test = mean_squared_error(y_test, y_pred_lasso)
r2_lasso_train = r2_score(y_train, y_train_lasso)
r2_lasso_test = r2_score(y_test, y_pred_lasso)
# Print the evaluation metrics for both models
print("Ridge Regression - Best Alpha:" , ridge_cv.best_params_['alpha'])
print("Ridge Mean Squared Error:",(mse_ridge_test))
print("Ridge R^2 Score:",(r2_ridge_test))
mse_percent_ridge = mse_ridge_test * 100
r2_percent_ridge = r2_ridge_test * 100
print("Ridge - Mean Squared Error: {:.2f}%".format(mse_percent_ridge))
print("Ridge - R-squared: {:.2f}%".format(r2_percent_ridge))

print("\nLasso Regression - Best Alpha:",lasso_cv.best_params_['alpha'])
print("Lasso Mean Squared Error:",(mse_lasso_test))
print("Lasso R^2 Score:",(r2_lasso_test))

mse_percent_lasso = mse_lasso_test * 100
r2_percent_lasso = r2_lasso_test * 100
print("Lasso - Mean Squared Error: {:.2f}%".format(mse_percent_lasso))
print("Lasso - R-squared: {:.2f}%".format(r2_percent_lasso))

#create a list of metric score of linear regression
list_lr=['LinearRegression',mse_lr_train,mse_lr_test,r2_lr_train,r2_lr_test]
#create a empty dataframe for metric score columns
score = pd.DataFrame(columns = ['Model' , 'Train MSE', 'Test MSE' , 'Train R2_Score', 'Test R2_Score'])
#add the rows to the dataframe of linearrgression
score.loc[len(score)]=list_lr
#create a list of ridge metric score after hyperparameter tuning
list_ridge=['Ridge',mse_ridge_train,mse_ridge_test,r2_ridge_train,r2_ridge_test]
#add the rows to the dataframe
score.loc[len(score)]=list_ridge
#create a list of lasso metric score after hyperparameter tuning
list_lasso=['Lasso',mse_lasso_train,mse_lasso_test,r2_lasso_train,r2_lasso_test]
#add the rows to the dataframe
score.loc[len(score)]=list_lasso
print(score)

"""In this code, the GridSearchCV hyperparameter optimisation technique was employed. GridSearchCV was chosen because it thoroughly searches through a specific hyperparameter space to discover the ideal hyperparameters that would result in the greatest model performance. It is a frequently used method for hyperparameter optimisation that assures that the optimal hyperparameters are identified within the defined parameter space.

following hyperparameter optimisation, we can see some improvement in the Ridge regression model. The MSE reduced from 0.0.03908 to 0.03907, but the R-squared score climbed from 0.1622 to 0.1623.

However, following hyperparameter optimisation, the MSE of the Lasso regression model increases somewhat from 0.04667 to 0.03907. The R-squared score, on the other hand, increased from -0.00013 to 0.1625.
"""

# Visualizing evaluation Metric Score chart
# ML Model - 2 Implementation
# define the decision tree model
model = DecisionTreeRegressor(random_state=42)

#fit the model
model.fit(X_train_scaled, y_train)

#predictions on the test set
y_pred = model.predict(X_test_scaled)

#evaluate the model
mse_DT = mean_squared_error(y_test, y_pred)
r2_DT = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse_DT)
print("R-squared: ", r2_DT)

#ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
#hyperparameter
h_param= {'max_depth': [None, 15, 20, 25],
              'min_samples_split': [20, 25, 30],
              'min_samples_leaf': [4, 8, 12]}

#grid search cv
grid_search = GridSearchCV(model, h_param, cv=5, scoring=mape_scorer)
grid_search.fit(X_train_scaled, y_train)
print('Best parameters:', grid_search.best_params_)

dt_best = DecisionTreeRegressor(max_depth=grid_search.best_params_['max_depth'],
                                    min_samples_split=grid_search.best_params_['min_samples_split'],
                                    min_samples_leaf=grid_search.best_params_['min_samples_leaf'],
                                    random_state=0)

# Fit the Algorithm
dt_best.fit(X_train_scaled, y_train)

#predict on the training model
dtr_train=dt_best.predict(X_train_scaled)

# Predict on the model
y_pred = dt_best.predict(X_test_scaled)
#evaluate the model
mse_dsT_train=mean_squared_error(y_train,dtr_train)
mse_dsT_test = mean_squared_error(y_test, y_pred)
r2_dsT_train = r2_score(y_train, dtr_train)
r2_dsT_test = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse_dsT_test)
print("R-squared: ", r2_dsT_test)

#create a list of decion tree regressor metric  score
dtr_list=['DecisionTree',mse_dsT_train,mse_dsT_test,r2_dsT_train,r2_dsT_test]
#add the rows by list
score.loc[len(score)]=dtr_list
score

"""he evaluation metrics improve after adopting hyperparameter optimisation approaches. The R-squared value has grown from 0.5232 to 0.5765, while the mean squared error has dropped from 0.02224 to 0.01975."""

# ML Model - 3 Implementation
rf = RandomForestRegressor(random_state=42)

# Fit the Algorithm
rf.fit(X_train_scaled, y_train)

# Predict on the model
y_pred = rf.predict(X_test_scaled)

#evaluate the model
mse_rf = mean_squared_error(y_test, y_pred)
r2_rf = r2_score(y_test, y_pred)

print("Mean squared error: ", mse_rf)
print("R-squared: ", r2_rf)

# Visualizing evaluation Metric Score chart
plt.scatter(y_test, y_pred)
plt.xlabel('Actual Target')
plt.ylabel('Predicted Target')
plt.title('Random Forest Regressor - Actual vs Predicted')
sns.regplot(x=y_test, y=y_pred, scatter=False, color='red')
plt.show()

# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
param_grid = { 'n_estimators': [100, 120, 150],
              'max_depth': [None, 1,2,3],
               'min_samples_leaf': [1, 2, 5],
               'max_features': ['auto', 'sqrt'],
               'bootstrap': [True, False] }

grid_search = GridSearchCV(rf, param_grid, cv=5, scoring=mape_scorer)
grid_search.fit(X_train_scaled, y_train)
print('Best parameters:', grid_search.best_params_)

# Fit the Algorithm
best_rf_model = grid_search.best_estimator_
best_rf_model.fit(X_train_scaled, y_train)

#Predict the train model
rf_train=best_rf_model.predict(X_train_scaled)

# Predict on the model
y_pred = best_rf_model.predict(X_test_scaled)

#evaluate the metric score
mse_rf_train = mean_squared_error(y_train, rf_train)
mse_rf_test = mean_squared_error(y_test, y_pred)
r2_rf_train = r2_score(y_train, rf_train)
r2_rf_test = r2_score(y_test, y_pred)


print('Mean Squared Error:', mse_rf_test)
print('R2 Score:', r2_rf_test)

#create a list of random forest regressor metric  score
rf_list=['Randomforrest',mse_rf_train,mse_rf_test,r2_rf_train,r2_rf_test]
#add the rows by list
score.loc[len(score)]=rf_list
score

# Visualizing evaluation Metric Score chart
# ML Model - 4 Implementation
# define the decision tree model
model = ExtraTreesRegressor(random_state=42)

#fit the model
model.fit(X_train_scaled, y_train)

#predictions on the test set
y_pred = model.predict(X_test_scaled)

#evaluate the model
mse_br = mean_squared_error(y_test, y_pred)
r2_br = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse_br)
print("R-squared: ", r2_br)

#ML Model - 4 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
#hyperparameter
h_param= { 'bootstrap': [True, False],
                          'max_depth': [70,100, None],
                          'criterion' :['squared_error'],
                          'max_features': ['log2', 'sqrt'],
                          'n_estimators': [10,1400,100]}

#grid search cv
grid_search = GridSearchCV(model, h_param, cv=5, scoring=mape_scorer)
grid_search.fit(X_train_scaled, y_train)
print('Best parameters:', grid_search.best_params_)

br_best = grid_search.best_estimator_

# Fit the Algorithm
br_best.fit(X_train_scaled, y_train)

#predict on the training model
br_train=dt_best.predict(X_train_scaled)

# Predict on the model
y_pred = br_best.predict(X_test_scaled)
#evaluate the model
mse_br_train=mean_squared_error(y_train,br_train)
mse_br_test = mean_squared_error(y_test, y_pred)
r2_br_train = r2_score(y_train, br_train)
r2_br_test = r2_score(y_test, y_pred)

print("Mean Absolute Percentage Error: ", mse_br_test)
print("R-squared: ", r2_br_test)

#create a list of extra tree regressor metric  score
br_list=['ExtraTreeRegressor',mse_br_train,mse_br_test,r2_br_train,r2_br_test]
#add the rows by list
score.loc[len(score)]=br_list
score

# ML Model - 6 Implementation
lgbm = LGBMRegressor(random_state=0)

# Fit the Algorithm
lgbm.fit(X_train_scaled, y_train)

# Predict on the model
y_pred = lgbm.predict(X_test_scaled)

#evaluate the model
mse_lgbm = mean_squared_error(y_test, y_pred)
r2_lgbm = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse_lgbm)
print("R-squared: ", r2_lgbm)

# ML Model - 6 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)
param_grid = param_grid = { 'learning_rate': [0.1],
                           'n_estimators': [50],
                            'max_depth': [8],
                            'colsample_bytree': [0.8],
                            'subsample': [0.8],
                            'min_child_samples': [5] }

grid_search = GridSearchCV(lgbm, param_grid, cv=5, scoring=mape_scorer)
grid_search.fit(X_train_scaled, y_train)
print('Best parameters:', grid_search.best_params_)

# Fit the Algorithm
best_lgbm_model = grid_search.best_estimator_
best_lgbm_model.fit(X_train_scaled, y_train)

#Predict the train model
lgbm_train=best_lgbm_model.predict(X_train_scaled)

# Predict on the model
y_pred = best_lgbm_model.predict(X_test_scaled)

#evaluate the metric score
mse_lgbm_train = mean_squared_error(y_train, lgbm_train)
mse_lgbm_test = mean_squared_error(y_test, y_pred)
r2_lgbm_train = r2_score(y_train, lgbm_train)
r2_lgbm_test = r2_score(y_test, y_pred)

print('Mean Squared Error:', mse_lgbm_test)
print('R2 Score:', r2_lgbm_test)

#create a list of lgbmregressor metric  score
lgbm_list=['LGBMRegressor',mse_lgbm_train,mse_lgbm_test,r2_lgbm_train,r2_lgbm_test]
#add the rows by list
score.loc[len(score)]=lgbm_list
score

# ML Model - 7 Implementation
estimators = [
     ('xgb', XGBRegressor()),
    ('etr', ExtraTreesRegressor()),
    ('random',RandomForestRegressor())
 ]
sr =StackingRegressor(estimators=estimators,
    final_estimator=ExtraTreesRegressor(n_estimators=1400,
                                          random_state=42),cv=5)
# Fit the Algorithm
sr.fit(X_train_scaled, y_train)

# Predict on the model
y_pred = sr.predict(X_test_scaled)
#Predict the train model
sr_train=sr.predict(X_train_scaled)


#evaluate the model
mse_sr_train = mean_squared_error(y_train, sr_train)
mse_sr = mean_squared_error(y_test, y_pred)
r2_sr_train = r2_score(y_train, sr_train)
r2_sr = r2_score(y_test, y_pred)

print("Mean Squared Error: ", mse_sr)
print("R-squared: ", r2_sr)

#create a list of stacking regressor metric  score
sr_list=['StackingRegressor',mse_sr_train,mse_sr,r2_sr_train,r2_sr]
#add the rows by list
score.loc[len(score)]=sr_list
score

fig,ax=plt.subplots(1,2,figsize=(15,10))
#plot the mse of all model
score.plot(x="Model", y=['Train MSE' , 'Test MSE'], kind="bar" , title = 'MSE Score Results',ax=ax[0])
#plot the r2_score of all model
score.plot(x="Model", y=['Train R2_Score' , 'Test R2_Score'], kind="bar" , title = 'R2 Score Results',ax=ax[1])

"""The ExtraTreeRegressor MODEL outperformed the other three models in terms of MEAN SQUARED ERROR and R-SQUARED value, with the lowest MSE and highest R-SQUARED value.

As a result, I'd go with the ExtraTreeRegressor model as the final prediction model.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor
from sklearn.metrics import roc_curve, auc
from lightgbm import LGBMRegressor
from sklearn.ensemble import StackingRegressor

# Create a binary classification target
df['Energy_Level'] = (df['Appliances'] > df['Appliances'].median()).astype(int)

# Features and target
X = df[['lights', 'temp_kitchen', 'hu_Kitchen', 'hour']]
y = df['Energy_Level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define regression models for the binary classification task
models = {
    "LinearRegression": LinearRegression(),
    "Ridge": Ridge(),
    "Lasso": Lasso(alpha=0.0001),
    "DecisionTree": DecisionTreeRegressor(max_depth=11, random_state=10),
    "RandomForest": RandomForestRegressor(n_estimators=50, random_state=10),
    "ExtraTreeRegressor": ExtraTreesRegressor(n_estimators=50, random_state=10),
    "LGBMRegressor": LGBMRegressor(n_estimators=100, random_state=10),
    "StackingRegressor": StackingRegressor(estimators=[
        ('lr', LinearRegression()),
        ('rf', RandomForestRegressor(n_estimators=10, random_state=10))
    ])
}

# Plot ROC curves
plt.figure(figsize=(10, 8))
for name, model in models.items():
    # Fit the model
    model.fit(X_train, y_train)
    # Get the predicted values (treated as scores for ROC)
    y_scores = model.predict(X_test)

    # Compute ROC curve and AUC
    fpr, tpr, _ = roc_curve(y_test, y_scores)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

# Plot diagonal line for random performance
plt.plot([0, 1], [0, 1], linestyle='--', color='black')
plt.title('ROC Curve for Regression Models as Classifiers')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor
from sklearn.metrics import accuracy_score, mean_squared_error
from lightgbm import LGBMRegressor

# Create a binary classification target
df['Energy_Level'] = (df['Appliances'] > df['Appliances'].median()).astype(int)

# Features and target
X = df[['lights', 'temp_kitchen', 'hu_Kitchen', 'hour']]
y = df['Energy_Level']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define regression models for the binary classification task
models = {
    "LinearRegression": LinearRegression(),
    "Ridge": Ridge(),
    "Lasso": Lasso(alpha=0.0001),
    "DecisionTree": DecisionTreeRegressor(max_depth=11, random_state=10),
    "RandomForest": RandomForestRegressor(n_estimators=50, random_state=10),
    "ExtraTreeRegressor": ExtraTreesRegressor(n_estimators=50, random_state=10),
    "LGBMRegressor": LGBMRegressor(n_estimators=100, random_state=10),
    "StackingRegressor": StackingRegressor(estimators=[
        ('lr', LinearRegression()),
        ('rf', RandomForestRegressor(n_estimators=10, random_state=10))
    ])
}

# Store accuracy and loss
accuracies = []
losses = []

for name, model in models.items():
    # Fit the model
    model.fit(X_train, y_train)

    # Get the predicted values
    y_scores = model.predict(X_test)

    # Threshold scores to get binary predictions
    y_pred = (y_scores > 0.5).astype(int)

    # Calculate accuracy
    acc = accuracy_score(y_test, y_pred)
    accuracies.append(acc)

    # Calculate loss (MSE)
    mse = mean_squared_error(y_test, y_scores)
    losses.append(mse)

    print(f"{name} - Accuracy: {acc:.4f}, Loss (MSE): {mse:.4f}")

# Plot accuracy and loss
x_labels = list(models.keys())

plt.figure(figsize=(14, 6))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.bar(x_labels, accuracies, color='skyblue')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xticks(rotation=45)

# Loss plot
plt.subplot(1, 2, 2)
plt.bar(x_labels, losses, color='orange')
plt.title('Model Loss (MSE)')
plt.ylabel('Loss (MSE)')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

"""**Accuracy**: ExtraTreeRegressor has the highest accuracy (0.8657), closely followed by RandomForest (0.8609) and StackingRegressor (0.8584).

**Loss (MSE)**: RandomForest has the lowest loss (0.1010), closely followed by StackingRegressor (0.1040).

The ExtraTreeRegressor is the best in terms of accuracy, while RandomForest is the best in terms of MSE

**Step 9: Model explainability**
"""

#install LIME
!pip install lime

import lime
from lime.lime_tabular import LimeTabularExplainer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor
from lightgbm import LGBMRegressor
import numpy as np
import matplotlib.pyplot as plt

# Prepare the data (replace 'df' with your DataFrame)
X = df[['lights', 'temp_kitchen', 'hu_Kitchen', 'hour']]  # Features
y = (df['Appliances'] > df['Appliances'].median()).astype(int)  # Binary target

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the models
models = {
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'DecisionTree': DecisionTreeRegressor(),
    'RandomForest': RandomForestRegressor(),
    'ExtraTreeRegressor': ExtraTreesRegressor(),
    'LGBMRegressor': LGBMRegressor(),
    'StackingRegressor': StackingRegressor(
        estimators=[('rf', RandomForestRegressor()), ('dt', DecisionTreeRegressor())], final_estimator=LinearRegression()
    ),
}

# Iterate over each model
for name, model in models.items():
    # Train the model
    model.fit(X_train, y_train)

    # Initialize LIME Explainer
    explainer = LimeTabularExplainer(
        training_data=np.array(X_train),
        training_labels=np.array(y_train),
        mode="classification",  # For binary classification
        feature_names=X.columns,
        class_names=["Low", "High"],  # Replace with the class names if different
        discretize_continuous=True
    )

    # Pick a sample to explain
    idx = 10  # Change index to pick a sample
    sample = X_test.iloc[idx]

    # Check if model has `predict_proba` (classification models)
    if hasattr(model, 'predict_proba'):
        model_predict = model.predict_proba
    else:
        # For regression models, we use predict and simulate the binary output
        model_predict = lambda x: np.column_stack([1 - model.predict(x), model.predict(x)])

    # Explain the prediction for the selected sample
    explanation = explainer.explain_instance(
        sample, model_predict, num_features=4  # num_features is the number of features to explain
    )

    # Visualize the explanation
    explanation.show_in_notebook(show_table=True, show_all=False)

    # Optionally, plot the explanation
    explanation.as_pyplot_figure()
    plt.show()

    print(f"Explanation for model: {name}")
    print(f"Prediction: {model.predict([sample])[0]}")
    print("\n")

"""the model is suggesting that based on the time of day (evening), the temperature in the kitchen, and the humidity level, there is a 75% chance of high appliance usage at this particular time, regardless of the lights being on or off.

**Step 10: Conclusion**

The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru), and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non predictive attributes (parameters).

1) Main aim of the project is to predict energy consumption of Appliances. First we analysed the data but the information from the data set is collected in regular interval of time so it's time series data. We are not implementing time series technique on the model because of less knowledge on time series.

2) Then we used the matplotlib and seaborn to do Exploratory Data Analysis on data by plotting different graphs like scatter-plot, barplot, boxplot, subplot and heat map. From this we got useful insights like:

Many columns in the dataset are not normally distributed and target column is also right skewed.
Dataset has many outliers and no null values.
We have hours column which is highly correlated with dependent variable and there are lot features that have lesser than 0.1 correlation with dependent variable and it is a non linear dataset.
Energy consumption in month of March is high and low in January and the increase in temp leads to more energy consumption.
Decrease in Humidity leads to increase in power consumption. Humidity is inversely proportional to dependent variable i.e Energy Consumption.
Hour of the Day is the most important influencing parameter for Energy consumption.
High Electricity consumption of >140Wh is observed during evening hours 16:00 to 20:00. Weekends (Saturdays and Sundays) also observed high consumption of Electricity. (> 25% than Weekdays)
lights have very low importance as a feature.
3) In feature selection we used variance threshold , f_regression and Pearson correlation matrix and using them we removed features that are not important for predicting dependent variable.

4) In feature engineering technique we removed outliers in our model.

5) Algorithms like Linearregression, Polynomial regression, Decision tree, Random forest, Gradient boosting ,XGBM and LGBM regression are used and cross validation hyperparameter tuning was done on the all models. By comparing all models we found that randomforest regressor performs good having high r2 score and MSE, RMSE value is also low for random forest. Some overfitting is happening because dataset is time series and we are not implementing time series concept.
"""